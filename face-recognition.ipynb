{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face_recognition\n",
      "  Using cached face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from face_recognition) (7.0.0)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in /home/sharif/.local/lib/python3.8/site-packages (from face_recognition) (0.3.0)\n",
      "Requirement already satisfied: Click>=6.0 in /usr/lib/python3/dist-packages (from face_recognition) (7.0)\n",
      "Requirement already satisfied: numpy in /home/sharif/.local/lib/python3.8/site-packages (from face_recognition) (1.19.2)\n",
      "Collecting dlib>=19.7\n",
      "  Using cached dlib-19.21.0.tar.gz (3.2 MB)\n",
      "Building wheels for collected packages: dlib\n",
      "  Building wheel for dlib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dlib: filename=dlib-19.21.0-cp38-cp38-linux_x86_64.whl size=4569592 sha256=2102c41dba20016d9c943933ede0871a0ac1174212340a30325f8bbe22ba26f4\n",
      "  Stored in directory: /home/sharif/.cache/pip/wheels/3a/4e/b6/77346839e430150a62d9b46bf7e0a37181fe01fd07d5d452a7\n",
      "Successfully built dlib\n",
      "Installing collected packages: dlib, face-recognition\n",
      "Successfully installed dlib-19.21.0 face-recognition-1.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = face_recognition.load_image_file('/home/sharif/Downloads/person.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(447, 626, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119 ms ± 998 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "face_locations = face_recognition.face_locations(img, 1, 'hog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50, 505, 86, 469)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face_location in face_locations:\n",
    "    top, right, bottom, left = face_location\n",
    "    face_image = img[top:bottom, left:right]\n",
    "    pil_image = Image.fromarray(face_image)\n",
    "    pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama_1 = face_recognition.load_image_file('/home/sharif/Downloads/obama_1.jpg')\n",
    "obama_2 = face_recognition.load_image_file('/home/sharif/Downloads/obama_2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01546987,  0.1569559 ,  0.02785688, -0.00923217,  0.08113039,\n",
       "        0.01126045, -0.07296725, -0.04151147,  0.23020627, -0.14516427,\n",
       "        0.27712896,  0.08687248, -0.17500061, -0.128298  ,  0.10592528,\n",
       "        0.14087629, -0.20931929, -0.06276845, -0.14124493, -0.05167423,\n",
       "       -0.00355518,  0.05528705,  0.10593718, -0.00403908, -0.12698376,\n",
       "       -0.35550603, -0.04027632, -0.13330169,  0.08456319, -0.14969391,\n",
       "       -0.07206588, -0.03101112, -0.19713376, -0.07508683, -0.01308344,\n",
       "       -0.03708704, -0.01672701,  0.0052041 ,  0.21341544,  0.10563297,\n",
       "       -0.14804865,  0.05574746, -0.05228482,  0.24236739,  0.25534445,\n",
       "        0.06207041,  0.0214946 , -0.05860372,  0.11759058, -0.24940138,\n",
       "        0.00199875,  0.11438918,  0.09364738,  0.05946638,  0.09871991,\n",
       "       -0.18065146, -0.02025658,  0.06538943, -0.12848304,  0.02852983,\n",
       "        0.03819505, -0.04128385, -0.01317581,  0.04924088,  0.22091971,\n",
       "        0.04171636, -0.11817814, -0.07143888,  0.09060337, -0.06101189,\n",
       "        0.01345774,  0.04570593, -0.11058165, -0.1854282 , -0.27642184,\n",
       "        0.03702863,  0.28834179,  0.12650402, -0.17144904,  0.04223065,\n",
       "       -0.13258235,  0.01782008,  0.04428591,  0.03968354, -0.08179864,\n",
       "       -0.03807358, -0.02613092,  0.02089742,  0.13270611,  0.0272452 ,\n",
       "       -0.02593002,  0.17400753, -0.0767189 ,  0.05502538, -0.0009979 ,\n",
       "       -0.00082804, -0.11609194, -0.03742921, -0.1115846 , -0.00346421,\n",
       "       -0.0249856 , -0.07565581, -0.00224958,  0.10223917, -0.22983508,\n",
       "        0.14309302, -0.00094004, -0.03410791,  0.04811577,  0.11986397,\n",
       "       -0.06766144, -0.0216506 ,  0.08085839, -0.27321562,  0.26200765,\n",
       "        0.25344262, -0.00204699,  0.14722447,  0.05212909,  0.0732649 ,\n",
       "       -0.06976341,  0.08214491, -0.1676182 , -0.1142509 , -0.00417052,\n",
       "        0.02096409,  0.06409721, -0.02419606])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obama_1_face_encoding = face_recognition.face_encodings(obama_1)[0]\n",
    "obama_1_face_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "obama_2_face_encoding = face_recognition.face_encodings(obama_2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_recognition.compare_faces([obama_1_face_encoding], obama_1_face_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The face recognition model is trained on adults and does not work very well on children. It tends to mix up children quite easy using the default comparison threshold of 0.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
